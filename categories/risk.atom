<?xml version='1.0' encoding='UTF-8'?>
<?xml-stylesheet href="https://smallsheds.garden/assets/xml/atom.xsl" type="text/xsl media="all"?>
<feed xml:lang="en" xmlns="http://www.w3.org/2005/Atom">
  <title>Joep Schuurkes (Posts about risk)</title>
  <id>https://smallsheds.garden/categories/risk.atom</id>
  <updated>2026-02-13T14:10:06Z</updated>
  <author>
    <name>Joep Schuurkes</name>
  </author>
  <link rel="self" type="application/atom+xml" href="https://smallsheds.garden/categories/risk.atom"/>
  <link rel="alternate" type="text/html" href="https://smallsheds.garden/categories/risk/"/>
  <generator uri="https://getnikola.com/">Nikola</generator>
  <entry>
    <title>Not continuous everything!</title>
    <id>https://smallsheds.garden/blog/2025/not-continuous-everything/</id>
    <updated>2025-12-21T00:00:00+01:00</updated>
    <published>2025-12-21T00:00:00+01:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2025/not-continuous-everything/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;In Chapter 18 of "Taking Testing Seriously" (I skipped ahead, sue me), &lt;a href="https://qualityremarks.com/"&gt;Keith Klain&lt;/a&gt; says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So much today is about "continuous everything" - continuous deployment, continuous integration - and speed. The pace at which people are doing things is really, really disruptive to thinking deeply about problems. Then the goal gets displaced from getting good products and services to customers quickly, and turns into, "How do we back something out quickly when we inevitably screw up?" It's continuous everything - except continuous thinking.&lt;br&gt;
&lt;em&gt;- Taking Testing Seriously, James Bach, Michael Bolton et al., 2025, p. 424&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He has a point. But I got there by first kind of disagreeing with what he said. Because "continuous everything" is not about speed. It's about risk. Or rather, about managing certain risks: the risk of (code) integration and the risks of delivery/deployment. And how fast you go, should not just be determined by those two specific risks. (Or even worse, by the fact that you just think it's really cool that you can release every commit to your users.) It should be determined by your overall risk appetite, which is a much broader perspective.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2025/not-continuous-everything/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="cicd" label="ci/cd"/>
    <category term="quality-engineering" label="quality engineering"/>
    <category term="risk" label="risk"/>
  </entry>
  <entry>
    <title>Being intentional about exploratory testing</title>
    <id>https://smallsheds.garden/blog/2024/being-intentional-about-exploratory-testing/</id>
    <updated>2024-11-09T00:00:00+01:00</updated>
    <published>2024-11-09T00:00:00+01:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2024/being-intentional-about-exploratory-testing/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;&lt;em&gt;This is the second post in a (to be) three-part series about my statement "The difference between a test case and a requirement is the moment of discovery."&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the previous post I &lt;a href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/#translated-requirements"&gt;distinguished&lt;/a&gt; test cases that are translated requirements from ones that aren't. This is something I learned from &lt;a href="https://www.workroom-productions.com/"&gt;James Lyndsay&lt;/a&gt;. As he describes in &lt;em&gt;&lt;a href="https://www.workroom-productions.com/why-exploration-has-a-place-in-any-strategy/"&gt;"Why Exploration has a Place in any Strategy"&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Some tests are designed to find risks. They're made on-the-fly and run once. Some are designed to tell us about retained value. They're made once, and run forever after. You need &lt;em&gt;both&lt;/em&gt;: they tell you different things.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The tests with a focus on value are based on requirements, on things we know we want, they are prescribed (as in: written before). The tests with a focus on risks are exploratory, they are based on our decisions in the moment, we look for surprises and decide how we feel about those surprises.&lt;/p&gt;
&lt;p&gt;One thing I've noticed through the years, is that a lot more exploratory testing is happening than we give credit for. It's hidden, a required but implicit part of the work. We do it, but we're not intentional about it.&lt;/p&gt;
&lt;p&gt;Today I want to argue that it pays to be more intentional about exploratory testing. Before I get there, however, I want to explain what exploratory testing is, because there are still plenty of misconceptions going around.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2024/being-intentional-about-exploratory-testing/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="quality-engineering" label="quality engineering"/>
    <category term="risk" label="risk"/>
    <category term="software-development" label="software development"/>
    <category term="software-testing" label="software testing"/>
  </entry>
  <entry>
    <title>Three thoughts on risk-based testing</title>
    <id>https://smallsheds.garden/blog/2022/three-thoughts-on-risk-based-testing/</id>
    <updated>2022-07-17T11:56:30+02:00</updated>
    <published>2022-07-17T11:56:30+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2022/three-thoughts-on-risk-based-testing/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;The past month I've been thinking about risk-based testing. This post collects three thoughts on risk-based testing I kept returning to.&lt;/p&gt;
&lt;h2&gt;If not based on risks, then based on what?&lt;/h2&gt;
&lt;p&gt;About a month ago I &lt;a href="https://twitter.com/j19sch/status/1533760354647523330"&gt;tweeted&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What are the alternatives to risk-based testing?&lt;br&gt;
Requirements-based? I'd argue that's a subset of risk-based.&lt;br&gt;
Unguided? That's either a bad idea ("we hope to get lucky") or aimed at the risk of unknown unknowns.&lt;br&gt;
Any other options? Because something about the term is bothering me.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My question was inspired by the &lt;a href="https://smallsheds.garden/slides/rtc2019-testing-types.html#/15/0/1"&gt;"opposite" heuristic&lt;/a&gt; from my talk about &lt;a href="https://smallsheds.garden/slides/rtc2019-testing-types.html#/"&gt;testing types&lt;/a&gt;: if we have some kind of category, what's the name for the things not in that category? Applied to risk-based testing: what's the name for testing that's not risk-based?&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2022/three-thoughts-on-risk-based-testing/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="coverage" label="coverage"/>
    <category term="risk" label="risk"/>
    <category term="software-testing" label="software testing"/>
    <category term="test-management" label="test management"/>
    <category term="test-strategy" label="test strategy"/>
  </entry>
  <entry>
    <title>Test strategy primer</title>
    <id>https://smallsheds.garden/blog/2019/test-strategy-primer/</id>
    <updated>2019-01-29T21:34:19+01:00</updated>
    <published>2019-01-29T21:34:19+01:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2019/test-strategy-primer/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;&lt;em&gt;I originally wrote this primer to share with people at work. The first section is intended to be generally applicable; the second not necessarily so. The main influences on this primer are:&lt;/em&gt;&lt;br&gt;
&lt;em&gt;- Rapid Software Testing's &lt;a href="https://www.satisfice.com/tools/htsm.pdf"&gt;Heuristic Test Strategy Model&lt;/a&gt;&lt;/em&gt;&lt;br&gt;
&lt;em&gt;- James Lyndsay's &lt;a href="http://www.workroom-productions.com/papers/Exploration%20and%20Strategy.pdf"&gt;Why Exploration has a place in any Strategy&lt;/a&gt;&lt;/em&gt;&lt;br&gt;
&lt;em&gt;- Rikard Edgren's &lt;a href="http://www.thetesteye.com/papers/TheLittleBlackBookOnTestDesign.pdf"&gt;Little Black Book on Test Design&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This document contains two sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why have a test strategy? - what is a test strategy and what's its purpose&lt;/li&gt;
&lt;li&gt;Test strategy checklist - checklist for describing your test strategy&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why have a test strategy?&lt;/h3&gt;
&lt;p&gt;The purpose of a test strategy is to answer the question: "How do we know that what we are building, is good enough?" As such, every team has a test strategy, even if it's only implicitly defined through the actions of the team members.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2019/test-strategy-primer/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="context-driven-testing" label="context-driven testing"/>
    <category term="risk" label="risk"/>
    <category term="test-management" label="test management"/>
    <category term="test-strategy" label="test strategy"/>
  </entry>
  <entry>
    <title>Why your Product Risk Analysis isn't</title>
    <id>https://smallsheds.garden/blog/2013/why-your-product-risk-analysis-isnt/</id>
    <updated>2013-06-23T14:34:36+02:00</updated>
    <published>2013-06-23T14:34:36+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2013/why-your-product-risk-analysis-isnt/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;Ok, going to try to keep this short and ranty (rantish?).&lt;/p&gt;
&lt;p&gt;Typical test advice is to do a Product Risk Analysis (PRA, mind the capitalisation!) and based on that you decide what to test and how thoroughly. The most common way to do a PRA is with a workshop. Put some people in a room with a lot of stickies, let them list all the risks they can think of and then have them score them. Et voilà, Product Risk Analysis is done!&lt;/p&gt;
&lt;p&gt;But that doesn't really make sense, now does it? If someone were to give you an object and asked you "What could possibly go wrong with this?", what would you do? Gather a bunch of people with some knowledge of the object, yet no actual experience with it and do a workshop imagining things that could go wrong? That's not an Analysis (capital A!), that's a SWAG – a scientific wild ass guess.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2013/why-your-product-risk-analysis-isnt/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="risk" label="risk"/>
    <category term="test-management" label="test management"/>
    <category term="test-reporting" label="test reporting"/>
    <category term="test-strategy" label="test strategy"/>
  </entry>
</feed>
