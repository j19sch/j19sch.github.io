<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Joep Schuurkes (Posts about exploratory testing)</title><link>https://smallsheds.garden/</link><description></description><atom:link href="https://smallsheds.garden/categories/exploratory-testing.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2024 &lt;a href="mailto:site@joep.slmail.me"&gt;Joep Schuurkes&lt;/a&gt; 
&lt;a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow" target="_blank"&gt;
&lt;img alt="Creative Commons License" style="border-width:0;margin: 0px 0px 0px 0px" src="https://licensebuttons.net/l/by/4.0/80x15.png" /&gt;
&lt;/a&gt;
</copyright><lastBuildDate>Mon, 25 Nov 2024 19:19:36 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Being intentional about exploratory testing</title><link>https://smallsheds.garden/blog/2024/being-intentional-about-exploratory-testing/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;This is the second post in a (to be) three-part series about my statement "The difference between a test case and a requirement is the moment of discovery."&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the previous post I &lt;a href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/#translated-requirements"&gt;distinguished&lt;/a&gt; test cases that are translated requirements from ones that aren't. This is something I learned from &lt;a href="https://www.workroom-productions.com/"&gt;James Lyndsay&lt;/a&gt;. As he describes in &lt;em&gt;&lt;a href="https://www.workroom-productions.com/why-exploration-has-a-place-in-any-strategy/"&gt;"Why Exploration has a Place in any Strategy"&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Some tests are designed to find risks. They're made on-the-fly and run once. Some are designed to tell us about retained value. They're made once, and run forever after. You need &lt;em&gt;both&lt;/em&gt;: they tell you different things.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The tests with a focus on value are based on requirements, on things we know we want, they are prescribed (as in: written before). The tests with a focus on risks are exploratory, they are based on our decisions in the moment, we look for surprises and decide how we feel about those surprises.&lt;/p&gt;
&lt;p&gt;One thing I've noticed through the years, is that a lot more exploratory testing is happening than we give credit for. It's hidden, a required but implicit part of the work. We do it, but we're not intentional about it.&lt;/p&gt;
&lt;p&gt;Today I want to argue that it pays to be more intentional about exploratory testing. Before I get there, however, I want to explain what exploratory testing is, because there are still plenty of misconceptions going around.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2024/being-intentional-about-exploratory-testing/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>quality engineering</category><category>software development</category><category>software testing</category><guid>https://smallsheds.garden/blog/2024/being-intentional-about-exploratory-testing/</guid><pubDate>Fri, 08 Nov 2024 23:00:00 GMT</pubDate></item><item><title>The difference between a test case and a requirement is the moment of discovery</title><link>https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;There are several straightforward ways to distinguish a test case from a requirement. A test case tells you how to check some kind of thing about the application, a requirement tells you that the application should do some kind of thing. A test case is written by a tester, a requirement by a business analyst. A test case takes the shape of an action and an evaluation of the result, a requirement takes the form of a sentence like "product ABC shall do XYZ."&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;A less straightforward, but more interesting way to distinguish a test case and a requirement, is this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The difference between a test case and a requirement is the moment of discovery.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this post I want to explore the meaning of that statement. In the next post I'll explore how looking at requirements and test cases in this way, can help us to do better testing. So this post will be a bit more philosophical, the next one more practical.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>quality engineering</category><category>semantics</category><category>software development</category><category>software testing</category><category>test cases</category><guid>https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/</guid><pubDate>Sun, 26 May 2024 22:00:00 GMT</pubDate></item><item><title>My five favorite testing questions</title><link>https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;Recently I realized there are a few testing questions I use a lot. They lie at the top of my testing toolbox, so to speak. Together they shape my testing style, making it easier for me to discover certain things, but probably also harder to find other kinds of things. So here are my five favorite testing questions, in no particular order.&lt;/p&gt;
&lt;h2&gt;What if there are zero, one, many, lots of this thing?&lt;/h2&gt;
&lt;p&gt;Last year I expressed my surprise &lt;a href="https://chaos.social/@joeposaurus/109427704814392787"&gt;on Mastodon&lt;/a&gt; how many times I've found bugs by asking the question: &lt;em&gt;"What if there are 0 / 1 / several / lots of this thing?"&lt;/em&gt; And if you're working closely enough to the code, you should also ask about "null".&lt;/p&gt;
&lt;p&gt;Quite a few people responded to my message. Turns out it's a &lt;a href="https://www.qwan.eu/2021/07/09/tdd-0-1-n.html"&gt;very&lt;/a&gt; &lt;a href="http://blog.wingman-sw.com/tdd-guided-by-zombies"&gt;common&lt;/a&gt; &lt;a href="https://mas.to/@zebulon/109428667658139893"&gt;pattern&lt;/a&gt; in TDD. And Brian Marick&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; remembered it &lt;a href="https://mstdn.social/@marick/109428042023981110"&gt;standing out&lt;/a&gt; when he was looking into fixed bugs in the Linux kernel they used in the '80s. Personally I learned it from Elisabeth Hendrickson's &lt;a href="https://web.archive.org/web/20150217124452/http://testobsessed.com/wp-content/uploads/2011/04/testheuristicscheatsheetv1.pdf"&gt;"Test Heuristics Cheat Sheet"&lt;/a&gt;, which found a &lt;a href="https://www.ministryoftesting.com/articles/ab1cd85c?s_id=14715206"&gt;new home&lt;/a&gt; last year at the Ministry of Testing.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>heuristics</category><category>software testing</category><guid>https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/</guid><pubDate>Wed, 03 May 2023 06:57:25 GMT</pubDate></item><item><title>Solving Black Box Puzzle 31 with data analysis</title><link>https://smallsheds.garden/blog/2019/solving-black-box-puzzle-31-with-data-analysis/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a href="https://twitter.com/workroomprds"&gt;James Lyndsay&lt;/a&gt; has created a number of amazing &lt;a href="http://blackboxpuzzles.workroomprds.com/"&gt;Black Box Puzzles&lt;/a&gt;: tiny applications that challenge you to figure out what they do. (You can support him in creating more of these at &lt;a href="https://www.patreon.com/workroomprds"&gt;his Patreon page&lt;/a&gt;.) Two of these Puzzles, &lt;a href="http://blackboxpuzzles.workroomprds.com/puzzle29/"&gt;29&lt;/a&gt; and &lt;a href="http://blackboxpuzzles.workroomprds.com/puzzle31/"&gt;31&lt;/a&gt;, not only have a GUI to explore, but also an API.&lt;/p&gt;
&lt;p&gt;And that gave me an idea. If you explore these Puzzles through their GUI, you start from the inputs. You try out different inputs in the hope of discovering a pattern in the outputs. And then that pattern feeds back into your exploration.&lt;br&gt;
With an API, however - and because of the nature of Puzzle 31 - it becomes easy to get the outputs for all possible combinations of inputs. Which means you can start your exploration from the outputs instead of the inputs.&lt;/p&gt;
&lt;p&gt;Before I tell you how and what I did, three important remarks.&lt;br&gt;
First of all, I will be spoiling the solution to the Puzzle in this blog post. So this is the right moment to go and solve &lt;a href="http://blackboxpuzzles.workroomprds.com/puzzle31/"&gt;Puzzle 31&lt;/a&gt; for yourself first. Or at least go play a bit with it, so you have an idea what the inputs and outputs are.&lt;br&gt;
Secondly, I had already solved the Puzzle through the GUI a few months ago. So it was more of a "Can I find the solution this way as well?" than a "Can I find the solution?" thing.&lt;br&gt;
Finally, the code and the spreadsheet I created (linked throughout, also available on GitHub &lt;a href="https://github.com/j19sch/blackbox-puzzle-31"&gt;here&lt;/a&gt;), are not very clean. I thought about tidying them up, but my two reasons for not doing so are (1) laziness; (2) the way they are now gives a more honest picture of what I did.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2019/solving-black-box-puzzle-31-with-data-analysis/"&gt;Read more…&lt;/a&gt; (18 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>black box puzzle</category><category>data analysis</category><category>exploratory testing</category><category>python</category><category>test automation</category><guid>https://smallsheds.garden/blog/2019/solving-black-box-puzzle-31-with-data-analysis/</guid><pubDate>Sun, 28 Apr 2019 11:16:34 GMT</pubDate></item><item><title>Three arguments against the verification-validation dichotomy</title><link>https://smallsheds.garden/blog/2015/three-arguments-against-the-verification-validation-dichotomy/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;Last week while talking with two colleagues, one of them mentioned the verification/validation thing. And I noticed it made me feel uneasy. Because I know well enough what is meant by the distinction, but on a practical level I simply can't relate to it. When I think about what I do as a software tester and how verification versus validation applies to it, nothing happens. Blank mind. Crickets. Tumbleweed.
So after giving it some thought, I present you with three arguments against the verification-validation dichotomy.&lt;/p&gt;
&lt;p&gt;First of course, we have the obligatory interlude of defining these two terms. A place to start is the Wikipedia page on &lt;a href="http://en.wikipedia.org/wiki/Software_verification_and_validation"&gt;Software verification and validation&lt;/a&gt;. Unfortunately it contains conflicting definitions, so if anyone cares enough, please do fix. Luckily there's also the general &lt;a href="http://en.wikipedia.org/wiki/Verification_and_validation"&gt;Verification and validation&lt;/a&gt; page of Wikipedia, which gives us (among others) the tl;dr version of the distinction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verification: &lt;em&gt;Are we building the product right?&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Validation: &lt;em&gt;Are we building the right product?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally there's the &lt;a href="http://www.istqb.org/downloads/finish/20/145.html"&gt;ISTQB glossary v2.4&lt;/a&gt; that borrows from ISO 9000:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verification: &lt;em&gt;Confirmation by examination and through provision of objective evidence that specified requirements have been fulfilled.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Validation: &lt;em&gt;Confirmation by examination and through provision of objective evidence that the requirements for a specific intended use or application have been fulfilled.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now on to the three arguments.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2015/three-arguments-against-the-verification-validation-dichotomy/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>semantics</category><category>verification and validation</category><guid>https://smallsheds.garden/blog/2015/three-arguments-against-the-verification-validation-dichotomy/</guid><pubDate>Tue, 24 Mar 2015 19:53:24 GMT</pubDate></item><item><title>Test cases, can't do 'm no more</title><link>https://smallsheds.garden/blog/2013/test-cases-cant-do-m-no-more/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;Continuing the style of my previous blog post...&lt;/p&gt;
&lt;p&gt;Some days ago I found myself no longer able to think in test cases while testing. Of course, it's not as if I was using test design techniques to generate test cases one day and woke up the next day to find myself unable to do it anymore. But still, about a week ago I figured I had explored enough to be able to write down the test cases I wanted to execute and found myself staring at a blank page (well ok, empty Excel sheet) feeling alienated from what I was planning to do.&lt;/p&gt;
&lt;p&gt;So what do I mean when saying "thinking in test cases". Simply put, you take a piece of functionality, let a test design technique loose on it and there you go: a set of test cases to execute. Combine test design techniques over the different pieces of functionality as required and you're all covered test strategy-wise. Or that's the idea.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2013/test-cases-cant-do-m-no-more/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>test cases</category><category>test management</category><guid>https://smallsheds.garden/blog/2013/test-cases-cant-do-m-no-more/</guid><pubDate>Sat, 06 Jul 2013 18:19:32 GMT</pubDate></item><item><title>Some thoughts after attending the 'Getting a Grip on Exploratory Testing' workshop</title><link>https://smallsheds.garden/blog/2012/some-thoughts-after-attending-the-getting-a-grip-on-exploratory-testing-workshop/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;About two weeks ago I attended &lt;a href="http://www.workroom-productions.com/"&gt;James Lyndsay&lt;/a&gt;'s 'Getting a Grip on Exploratory Testing' workshop in Amsterdam. So it's about time to write something about it…&lt;/p&gt;
&lt;p&gt;Now one of the things I dislike about workshop blog posts is that people will say "It was great! And person X is such a good trainer!" without saying much about the content of the workshop. However, I find myself now writing this post and thinking: I shouldn't post a full summary of the workshop. Not that it would spoil too much for any future attendee: most of the workshop consists of exercises and discussion. But posting a summary of the workshop that James has put a lot of effort in to create, just doesn't feel right. So let me just say this: the workshop was great and James is such a good trainer! :-D&lt;/p&gt;
&lt;p&gt;Now that's out of the way, there are a few things from the workshop I'd like to share. Of course, the usual disclaimer applies: these are my thoughts on what was presented during the workshop. Any misrepresentations are my responsibility.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2012/some-thoughts-after-attending-the-getting-a-grip-on-exploratory-testing-workshop/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>software testing</category><category>workshop</category><guid>https://smallsheds.garden/blog/2012/some-thoughts-after-attending-the-getting-a-grip-on-exploratory-testing-workshop/</guid><pubDate>Sun, 29 Apr 2012 17:55:30 GMT</pubDate></item><item><title>The irony of scripted testing</title><link>https://smallsheds.garden/blog/2012/the-irony-of-scripted-testing/</link><dc:creator>Joep Schuurkes</dc:creator><description>&lt;div&gt;&lt;p&gt;A bit over a week ago, &lt;a href="https://twitter.com/jamesmarcusbach/status/185816224075227137"&gt;James Bach posted on twitter&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"This video shows a nice simple contrast between heavy scripted testing and exploratory testing &lt;a href="http://youtu.be/PxTqjAwM2Pw"&gt;http://youtu.be/PxTqjAwM2Pw&lt;/a&gt;"&lt;br&gt;
- James Bach (@jamesmarcusbach) March 30, 2012&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So I watched the video, hoping to see something that would make me go 'Cool!', but instead I went 'Hmmm.'&lt;/p&gt;
&lt;p&gt;First let me say that this video does get a few things right:&lt;br&gt;
- Exploratory testing can be structured by using charters.&lt;br&gt;
- Exploratory testing allows you to easily change your test approach based on your test results.&lt;br&gt;
- Exploratory testing is very adaptable when confronted with inaccurate or changing requirements.&lt;br&gt;
Yet notice how the above only talks about exploratory testing, because for every thing the video gets right about exploratory testing, it gets something wrong about scripted testing – or rather about how scripted testing works in practice.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2012/the-irony-of-scripted-testing/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>exploratory testing</category><category>software testing</category><guid>https://smallsheds.garden/blog/2012/the-irony-of-scripted-testing/</guid><pubDate>Mon, 09 Apr 2012 21:16:17 GMT</pubDate></item></channel></rss>