<?xml version='1.0' encoding='UTF-8'?>
<?xml-stylesheet href="https://smallsheds.garden/assets/xml/atom.xsl" type="text/xsl media="all"?>
<feed xml:lang="en" xmlns="http://www.w3.org/2005/Atom">
  <title>Joep Schuurkes (Posts about exploratory testing)</title>
  <id>https://smallsheds.garden/categories/exploratory-testing.atom</id>
  <updated>2024-10-13T13:46:17Z</updated>
  <author>
    <name>Joep Schuurkes</name>
  </author>
  <link rel="self" type="application/atom+xml" href="https://smallsheds.garden/categories/exploratory-testing.atom"/>
  <link rel="alternate" type="text/html" href="https://smallsheds.garden/categories/exploratory-testing/"/>
  <generator uri="https://getnikola.com/">Nikola</generator>
  <entry>
    <title>The difference between a test case and a requirement is the moment of discovery</title>
    <id>https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/</id>
    <updated>2024-05-27T00:00:00+02:00</updated>
    <published>2024-05-27T00:00:00+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;There are several straightforward ways to distinguish a test case from a requirement. A test case tells you how to check some kind of thing about the application, a requirement tells you that the application should do some kind of thing. A test case is written by a tester, a requirement by a business analyst. A test case takes the shape of an action and an evaluation of the result, a requirement takes the form of a sentence like "product ABC shall do XYZ."&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;A less straightforward, but more interesting way to distinguish a test case and a requirement, is this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The difference between a test case and a requirement is the moment of discovery.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this post I want to explore the meaning of that statement. In the next post I'll explore how looking at requirements and test cases in this way, can help us to do better testing. So this post will be a bit more philosophical, the next one more practical.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2024/the-difference-between-a-test-case-and-a-requirement-is-the-moment-of-discovery/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="quality-engineering" label="quality engineering"/>
    <category term="semantics" label="semantics"/>
    <category term="software-development" label="software development"/>
    <category term="software-testing" label="software testing"/>
    <category term="test-cases" label="test cases"/>
  </entry>
  <entry>
    <title>My five favorite testing questions</title>
    <id>https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/</id>
    <updated>2023-05-03T08:57:25+02:00</updated>
    <published>2023-05-03T08:57:25+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;Recently I realized there are a few testing questions I use a lot. They lie at the top of my testing toolbox, so to speak. Together they shape my testing style, making it easier for me to discover certain things, but probably also harder to find other kinds of things. So here are my five favorite testing questions, in no particular order.&lt;/p&gt;
&lt;h2&gt;What if there are zero, one, many, lots of this thing?&lt;/h2&gt;
&lt;p&gt;Last year I expressed my surprise &lt;a href="https://chaos.social/@joeposaurus/109427704814392787"&gt;on Mastodon&lt;/a&gt; how many times I've found bugs by asking the question: &lt;em&gt;"What if there are 0 / 1 / several / lots of this thing?"&lt;/em&gt; And if you're working closely enough to the code, you should also ask about "null".&lt;/p&gt;
&lt;p&gt;Quite a few people responded to my message. Turns out it's a &lt;a href="https://www.qwan.eu/2021/07/09/tdd-0-1-n.html"&gt;very&lt;/a&gt; &lt;a href="http://blog.wingman-sw.com/tdd-guided-by-zombies"&gt;common&lt;/a&gt; &lt;a href="https://mas.to/@zebulon/109428667658139893"&gt;pattern&lt;/a&gt; in TDD. And Brian Marick&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; remembered it &lt;a href="https://mstdn.social/@marick/109428042023981110"&gt;standing out&lt;/a&gt; when he was looking into fixed bugs in the Linux kernel they used in the '80s. Personally I learned it from Elisabeth Hendrickson's &lt;a href="https://web.archive.org/web/20150217124452/http://testobsessed.com/wp-content/uploads/2011/04/testheuristicscheatsheetv1.pdf"&gt;"Test Heuristics Cheat Sheet"&lt;/a&gt;, which found a &lt;a href="https://www.ministryoftesting.com/articles/ab1cd85c?s_id=14715206"&gt;new home&lt;/a&gt; last year at the Ministry of Testing.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2023/my-five-favorite-testing-questions/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="heuristics" label="heuristics"/>
    <category term="software-testing" label="software testing"/>
  </entry>
  <entry>
    <title>Solving Black Box Puzzle 31 with data analysis</title>
    <id>https://smallsheds.garden/blog/2019/solving-black-box-puzzle-31-with-data-analysis/</id>
    <updated>2019-04-28T13:16:34+02:00</updated>
    <published>2019-04-28T13:16:34+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2019/solving-black-box-puzzle-31-with-data-analysis/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;&lt;a href="https://twitter.com/workroomprds"&gt;James Lyndsay&lt;/a&gt; has created a number of amazing &lt;a href="http://blackboxpuzzles.workroomprds.com/"&gt;Black Box Puzzles&lt;/a&gt;: tiny applications that challenge you to figure out what they do. (You can support him in creating more of these at &lt;a href="https://www.patreon.com/workroomprds"&gt;his Patreon page&lt;/a&gt;.) Two of these Puzzles, &lt;a href="http://blackboxpuzzles.workroomprds.com/puzzle29/"&gt;29&lt;/a&gt; and &lt;a href="http://blackboxpuzzles.workroomprds.com/puzzle31/"&gt;31&lt;/a&gt;, not only have a GUI to explore, but also an API.&lt;/p&gt;
&lt;p&gt;And that gave me an idea. If you explore these Puzzles through their GUI, you start from the inputs. You try out different inputs in the hope of discovering a pattern in the outputs. And then that pattern feeds back into your exploration.&lt;br&gt;
With an API, however - and because of the nature of Puzzle 31 - it becomes easy to get the outputs for all possible combinations of inputs. Which means you can start your exploration from the outputs instead of the inputs.&lt;/p&gt;
&lt;p&gt;Before I tell you how and what I did, three important remarks.&lt;br&gt;
First of all, I will be spoiling the solution to the Puzzle in this blog post. So this is the right moment to go and solve &lt;a href="http://blackboxpuzzles.workroomprds.com/puzzle31/"&gt;Puzzle 31&lt;/a&gt; for yourself first. Or at least go play a bit with it, so you have an idea what the inputs and outputs are.&lt;br&gt;
Secondly, I had already solved the Puzzle through the GUI a few months ago. So it was more of a "Can I find the solution this way as well?" than a "Can I find the solution?" thing.&lt;br&gt;
Finally, the code and the spreadsheet I created (linked throughout, also available on GitHub &lt;a href="https://github.com/j19sch/blackbox-puzzle-31"&gt;here&lt;/a&gt;), are not very clean. I thought about tidying them up, but my two reasons for not doing so are (1) laziness; (2) the way they are now gives a more honest picture of what I did.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2019/solving-black-box-puzzle-31-with-data-analysis/"&gt;Read more…&lt;/a&gt; (18 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="black-box-puzzle" label="black box puzzle"/>
    <category term="data-analysis" label="data analysis"/>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="python" label="python"/>
    <category term="test-automation" label="test automation"/>
  </entry>
  <entry>
    <title>Three arguments against the verification-validation dichotomy</title>
    <id>https://smallsheds.garden/blog/2015/three-arguments-against-the-verification-validation-dichotomy/</id>
    <updated>2015-03-24T20:53:24+01:00</updated>
    <published>2015-03-24T20:53:24+01:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2015/three-arguments-against-the-verification-validation-dichotomy/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;Last week while talking with two colleagues, one of them mentioned the verification/validation thing. And I noticed it made me feel uneasy. Because I know well enough what is meant by the distinction, but on a practical level I simply can't relate to it. When I think about what I do as a software tester and how verification versus validation applies to it, nothing happens. Blank mind. Crickets. Tumbleweed.
So after giving it some thought, I present you with three arguments against the verification-validation dichotomy.&lt;/p&gt;
&lt;p&gt;First of course, we have the obligatory interlude of defining these two terms. A place to start is the Wikipedia page on &lt;a href="http://en.wikipedia.org/wiki/Software_verification_and_validation"&gt;Software verification and validation&lt;/a&gt;. Unfortunately it contains conflicting definitions, so if anyone cares enough, please do fix. Luckily there's also the general &lt;a href="http://en.wikipedia.org/wiki/Verification_and_validation"&gt;Verification and validation&lt;/a&gt; page of Wikipedia, which gives us (among others) the tl;dr version of the distinction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verification: &lt;em&gt;Are we building the product right?&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Validation: &lt;em&gt;Are we building the right product?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally there's the &lt;a href="http://www.istqb.org/downloads/finish/20/145.html"&gt;ISTQB glossary v2.4&lt;/a&gt; that borrows from ISO 9000:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verification: &lt;em&gt;Confirmation by examination and through provision of objective evidence that specified requirements have been fulfilled.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Validation: &lt;em&gt;Confirmation by examination and through provision of objective evidence that the requirements for a specific intended use or application have been fulfilled.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now on to the three arguments.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2015/three-arguments-against-the-verification-validation-dichotomy/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="semantics" label="semantics"/>
    <category term="verification-and-validation" label="verification and validation"/>
  </entry>
  <entry>
    <title>Test cases, can't do 'm no more</title>
    <id>https://smallsheds.garden/blog/2013/test-cases-cant-do-m-no-more/</id>
    <updated>2013-07-06T20:19:32+02:00</updated>
    <published>2013-07-06T20:19:32+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2013/test-cases-cant-do-m-no-more/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;Continuing the style of my previous blog post...&lt;/p&gt;
&lt;p&gt;Some days ago I found myself no longer able to think in test cases while testing. Of course, it's not as if I was using test design techniques to generate test cases one day and woke up the next day to find myself unable to do it anymore. But still, about a week ago I figured I had explored enough to be able to write down the test cases I wanted to execute and found myself staring at a blank page (well ok, empty Excel sheet) feeling alienated from what I was planning to do.&lt;/p&gt;
&lt;p&gt;So what do I mean when saying "thinking in test cases". Simply put, you take a piece of functionality, let a test design technique loose on it and there you go: a set of test cases to execute. Combine test design techniques over the different pieces of functionality as required and you're all covered test strategy-wise. Or that's the idea.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2013/test-cases-cant-do-m-no-more/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="test-cases" label="test cases"/>
    <category term="test-management" label="test management"/>
  </entry>
  <entry>
    <title>Some thoughts after attending the 'Getting a Grip on Exploratory Testing' workshop</title>
    <id>https://smallsheds.garden/blog/2012/some-thoughts-after-attending-the-getting-a-grip-on-exploratory-testing-workshop/</id>
    <updated>2012-04-29T19:55:30+02:00</updated>
    <published>2012-04-29T19:55:30+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2012/some-thoughts-after-attending-the-getting-a-grip-on-exploratory-testing-workshop/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;About two weeks ago I attended &lt;a href="http://www.workroom-productions.com/"&gt;James Lyndsay&lt;/a&gt;'s 'Getting a Grip on Exploratory Testing' workshop in Amsterdam. So it's about time to write something about it…&lt;/p&gt;
&lt;p&gt;Now one of the things I dislike about workshop blog posts is that people will say "It was great! And person X is such a good trainer!" without saying much about the content of the workshop. However, I find myself now writing this post and thinking: I shouldn't post a full summary of the workshop. Not that it would spoil too much for any future attendee: most of the workshop consists of exercises and discussion. But posting a summary of the workshop that James has put a lot of effort in to create, just doesn't feel right. So let me just say this: the workshop was great and James is such a good trainer! :-D&lt;/p&gt;
&lt;p&gt;Now that's out of the way, there are a few things from the workshop I'd like to share. Of course, the usual disclaimer applies: these are my thoughts on what was presented during the workshop. Any misrepresentations are my responsibility.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2012/some-thoughts-after-attending-the-getting-a-grip-on-exploratory-testing-workshop/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="software-testing" label="software testing"/>
    <category term="workshop" label="workshop"/>
  </entry>
  <entry>
    <title>The irony of scripted testing</title>
    <id>https://smallsheds.garden/blog/2012/the-irony-of-scripted-testing/</id>
    <updated>2012-04-09T23:16:17+02:00</updated>
    <published>2012-04-09T23:16:17+02:00</published>
    <author>
      <name>Joep Schuurkes</name>
    </author>
    <link rel="alternate" type="text/html" href="https://smallsheds.garden/blog/2012/the-irony-of-scripted-testing/"/>
    <summary type="html">&lt;div&gt;&lt;p&gt;A bit over a week ago, &lt;a href="https://twitter.com/jamesmarcusbach/status/185816224075227137"&gt;James Bach posted on twitter&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"This video shows a nice simple contrast between heavy scripted testing and exploratory testing &lt;a href="http://youtu.be/PxTqjAwM2Pw"&gt;http://youtu.be/PxTqjAwM2Pw&lt;/a&gt;"&lt;br&gt;
- James Bach (@jamesmarcusbach) March 30, 2012&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So I watched the video, hoping to see something that would make me go 'Cool!', but instead I went 'Hmmm.'&lt;/p&gt;
&lt;p&gt;First let me say that this video does get a few things right:&lt;br&gt;
- Exploratory testing can be structured by using charters.&lt;br&gt;
- Exploratory testing allows you to easily change your test approach based on your test results.&lt;br&gt;
- Exploratory testing is very adaptable when confronted with inaccurate or changing requirements.&lt;br&gt;
Yet notice how the above only talks about exploratory testing, because for every thing the video gets right about exploratory testing, it gets something wrong about scripted testing – or rather about how scripted testing works in practice.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://smallsheds.garden/blog/2012/the-irony-of-scripted-testing/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</summary>
    <category term="exploratory-testing" label="exploratory testing"/>
    <category term="software-testing" label="software testing"/>
  </entry>
</feed>
